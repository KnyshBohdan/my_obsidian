Polynomial Features are generated by raising existing features to a power or by creating interaction terms between them. This technique is particularly useful for capturing non-linear relationships in the data.

## Definition

Polynomial Features are mathematical transformations applied to original features in the dataset. They are represented as:

$$Polynomial \ Feature \ = x^n_i \ or \ x_i * x_j$$

where xixi​ and xjxj​ are original features, and nn is the degree of the polynomial.

## Types of Polynomial Features

1. **Univariate Polynomial Features**: Generated by raising a single feature to a power.
    - Example: x2,x3,…
2. **Multivariate Polynomial Features**: Generated by creating interaction terms between two or more features.
    - Example: x×y,x2×y,…

## Use Cases

1. **Linear Regression**: To capture non-linear relationships.
2. **Classification**: To create decision boundaries that are not linear.
3. **Time Series**: To model non-linear trends.

## Advantages and Limitations

- **Advantages**: Captures non-linear relationships, improves model performance.
- **Limitations**: Increases model complexity, risk of overfitting.

## How to Generate Polynomial Features

In Python, the `PolynomialFeatures` class from `sklearn.preprocessing` can be used to generate polynomial features.

`from sklearn.preprocessing import PolynomialFeatures
`poly = PolynomialFeatures(degree=2)`
`poly.fit_transform(X)`

## Connection to Other Topics

- **[[Feature Generation]]**: Polynomial features are a subset of feature generation techniques.
- **[[Machine Learning]]**: Commonly used in various machine learning algorithms.
- **[[Feature Engineering]]**: An advanced technique in the feature engineering pipeline.